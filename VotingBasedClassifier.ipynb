{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import cv2\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from numpy import ndarray\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "def read_images(dataset_path):\n",
    "    # Image Parameters\n",
    "    image_height = 14 #CHANGE HERE, the image height to be resized to\n",
    "    image_width = 14 #CHANGE HERE, the image width to be resized to\n",
    "\n",
    "    imagepaths, labels = list(), list()\n",
    "\n",
    "    # An ID will be affected to each sub-folders by alphabetical order\n",
    "    label = 0\n",
    "    # List the directory\n",
    "    try:  # Python 2\n",
    "        classes = sorted(os.walk(dataset_path).next()[1])\n",
    "    except Exception:  # Python 3\n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "\n",
    "    # List each sub-directory (the classes)\n",
    "    for c in classes:\n",
    "        c_dir = os.path.join(dataset_path, c)\n",
    "\n",
    "        try:  # Python 2\n",
    "            walk = os.walk(c_dir).next()\n",
    "\n",
    "        except Exception:  # Python 3\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "        # Add each image to the training set\n",
    "\n",
    "        for sample in walk[2]:\n",
    "            # Only keeps jpeg images\n",
    "            if sample.endswith('.jpg'):\n",
    "                img = cv2.imread(os.path.join(c_dir, sample))\n",
    "                img = cv2.resize(img,(image_height,image_width),interpolation = cv2.INTER_AREA)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                imagepaths.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "        label += 1\n",
    "\n",
    "    print (len(imagepaths))\n",
    "    print (len(labels))\n",
    "\n",
    "    return imagepaths, labels\n",
    "\n",
    "def read_orignalimages(dataset_path):\n",
    "    # Image Parameters\n",
    "    image_height = 14 #CHANGE HERE, the image height to be resized to\n",
    "    image_width = 14 #CHANGE HERE, the image width to be resized to\n",
    "\n",
    "    imagepaths, labels = list(), list()\n",
    "\n",
    "    # An ID will be affected to each sub-folders by alphabetical order\n",
    "    label = 0\n",
    "    # List the directory\n",
    "    try:  # Python 2\n",
    "        classes = sorted(os.walk(dataset_path).next()[1])\n",
    "    except Exception:  # Python 3\n",
    "        classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "\n",
    "    # List each sub-directory (the classes)\n",
    "    for c in classes:\n",
    "        c_dir = os.path.join(dataset_path, c)\n",
    "\n",
    "        try:  # Python 2\n",
    "            walk = os.walk(c_dir).next()\n",
    "\n",
    "        except Exception:  # Python 3\n",
    "            walk = os.walk(c_dir).__next__()\n",
    "        # Add each image to the training set\n",
    "\n",
    "        for sample in walk[2]:\n",
    "            # Only keeps jpeg images\n",
    "            if sample.endswith('.png'):\n",
    "                img = cv2.imread(os.path.join(c_dir, sample))\n",
    "                img = cv2.resize(img,(image_height,image_width),interpolation = cv2.INTER_AREA)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                imagepaths.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "        label += 1\n",
    "\n",
    "    print (len(imagepaths))\n",
    "    print (len(labels))\n",
    "\n",
    "    return imagepaths, labels\n",
    "\n",
    "Orignal_Path = r'' #The dataset file or root folder path. \n",
    "LL_Path = r'' #The dataset file or root folder path.\n",
    "LH_Path = r'' #The dataset file or root folder path.\n",
    "HL_Path = r'' #The dataset file or root folder path.\n",
    "HH_Path = r'' #The dataset file or root folder path.\n",
    "LL_input, LLy_input = read_images(LL_Path)\n",
    "LH_input, LHy_input = read_images(LH_Path)\n",
    "HL_input, HLy_input = read_images(HL_Path)\n",
    "HH_input, HHy_input = read_images(HH_Path)\n",
    "Orignal_input, Orignaly_input=read_orignalimages(Orignal_Path)\n",
    "\n",
    "LL_input = np.asarray(LL_input)\n",
    "LL_input = (LL_input.astype(np.float32) - LL_input.mean()) / LL_input.std()\n",
    "LL_input = LL_input.astype(np.float32)\n",
    "LL_input = np.expand_dims(LL_input, axis=1)\n",
    "LL_input = torch.tensor(LL_input)\n",
    "\n",
    "LH_input = np.asarray(LH_input)\n",
    "LH_input = (LH_input.astype(np.float32) - LH_input.mean()) / LH_input.std()\n",
    "LH_input = LH_input.astype(np.float32) \n",
    "LH_input = np.expand_dims(LH_input, axis=1)\n",
    "LH_input = torch.tensor(LH_input)\n",
    "\n",
    "HL_input = np.asarray(HL_input)\n",
    "HL_input = (HL_input.astype(np.float32) - HL_input.mean()) / HL_input.std()\n",
    "HL_input = HL_input.astype(np.float32) \n",
    "HL_input = np.expand_dims(HL_input, axis=1)\n",
    "HL_input = torch.tensor(HL_input)\n",
    "\n",
    "HH_input = np.asarray(HH_input)\n",
    "HH_input = (HH_input.astype(np.float32) - HH_input.mean()) / HH_input.std()\n",
    "HH_input = HH_input.astype(np.float32) \n",
    "HH_input = np.expand_dims(HH_input, axis=1)\n",
    "HH_input = torch.tensor(HH_input)\n",
    "\n",
    "Orignal_input = np.asarray(Orignal_input)\n",
    "Orignal_input = (Orignal_input.astype(np.float32) - Orignal_input.mean()) / Orignal_input.std()\n",
    "Orignal_input= Orignal_input.astype(np.float32) \n",
    "Orignal_input = np.expand_dims(Orignal_input, axis=1)\n",
    "Orignal_input = torch.tensor(Orignal_input)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "        w = self.tensors[2][index]\n",
    "        h = self.tensors[3][index]\n",
    "        z = self.tensors[4][index]\n",
    "      \n",
    "        return x, y,w,h,z\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)\n",
    "\n",
    "def min_max_normalization(tensor):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (1 - 0) + 0\n",
    "    return tensor\n",
    "\n",
    "train_dataset_normal = CustomTensorDataset(tensors=(LL_input, LH_input,HL_input,HH_input,Orignal_input), transform=None)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_normal , batch_size=200)\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "LL_input, LH_input, HL_input, HH_input, Orignal_input = dataiter.next()\n",
    "\n",
    "\n",
    "LL_input = LL_input.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(LL_input[0])\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "LH_input = LH_input.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(LH_input[0])\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "HL_input = HL_input.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(HL_input[0])\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "HH_input = HH_input.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(HH_input[0])\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "Orignal_input = Orignal_input.numpy()\n",
    "\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(Orignal_input[0])\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H1, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(H1, D_out)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.linear1(x)) \n",
    "        x = self.dropout1(x)\n",
    "        # we need raw output in case of multiclass classification so not using any activation function\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "model1 = Classifier(196, 20, 10)\n",
    "model2 = Classifier(196, 20, 10)\n",
    "model3 = Classifier(196, 20, 10)\n",
    "model4 = Classifier(196, 20, 10)\n",
    "model5 = Classifier(196, 20, 10)\n",
    "\n",
    "model1.load_state_dict(torch.load('D:\\Faheem\\model_save\\WithDroput20\\MNISTLL20%drop20softmax.pth'))\n",
    "model2.load_state_dict(torch.load('D:\\Faheem\\model_save\\WithDroput20\\MNISTLH20%drop20softmax.pth'))\n",
    "model3.load_state_dict(torch.load('D:\\Faheem\\model_save\\WithDroput20\\MNISTHL20%drop20softmax.pth'))\n",
    "model4.load_state_dict(torch.load('D:\\Faheem\\model_save\\WithDroput20\\MNISTHH20%drop20softmax.pth'))\n",
    "model5.load_state_dict(torch.load('D:\\Faheem\\model_save\\WithDroput20\\MNISTOrignal20%drop20softmax.pth'))\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "LL = ndarray((10000,10),float)\n",
    "LH = ndarray((10000,10),float)\n",
    "HL = ndarray((10000,10),float)\n",
    "HH = ndarray((10000,10),float)\n",
    "orignal = ndarray((10000,10),float)\n",
    "i=0\n",
    "for data in train_loader:\n",
    "    #print(\"Length of data\",len(data))\n",
    "    LL_input,LH_input,HL_input,HH_input,Orignal_input = data\n",
    "    LL_input = LL_input.view(LL_input.shape[0], -1)\n",
    "    LH_input = LH_input.view(LH_input.shape[0], -1)\n",
    "    HL_input = HL_input.view(HL_input.shape[0], -1)\n",
    "    HH_input = HH_input.view(HH_input.shape[0], -1)\n",
    "    Orignal_input = Orignal_input.view(Orignal_input.shape[0], -1) \n",
    "    #rint(Orignal_input.shape)\n",
    "    output1 = model1(Orignal_input)\n",
    "    #print(output1)\n",
    "    arr=output1.data.cpu().numpy()\n",
    "    #print(LL[:,:].shape)\n",
    "    LL[:,:]=arr\n",
    "    #print('Values in LL_Model',arr)\n",
    "    np.savetxt(\"output1.csv\",LL, delimiter=\", \",header='0,1,2,3,4,5,6,7,8,9',newline='\\n')\n",
    "    _, pred1 = torch.max(output1, 1)\n",
    "    output2 = model2(Orignal_input)\n",
    "    arr1=output2.data.cpu().numpy()\n",
    "    LH[:,:]=arr1\n",
    "    np.savetxt(\"output2.csv\", LH, delimiter=\", \",header='0,1,2,3,4,5,6,7,8,9',newline='\\n')\n",
    "    _, pred2 = torch.max(output2, 1)\n",
    "    output3 = model3(Orignal_input)\n",
    "    arr3=output3.data.cpu().numpy()\n",
    "    HL[:,:]=arr3\n",
    "    np.savetxt(\"output3.csv\", HL, delimiter=\", \",header='0,1,2,3,4,5,6,7,8,9',newline='\\n')\n",
    "    _, pred3 = torch.max(output2, 1)\n",
    "    output4 = model4(Orignal_input)\n",
    "    arr4=output4.data.cpu().numpy()\n",
    "    #print('Values in LH_Model',arr4)\n",
    "    HH[:,:]=arr4\n",
    "    _, pred4 = torch.max(output4, 1)\n",
    "    np.savetxt(\"output4.csv\", HH, delimiter=\", \",header='0,1,2,3,4,5,6,7,8,9',newline='\\n')\n",
    "    output5 = model5(Orignal_input)\n",
    "    arr5=output5.data.cpu().numpy()\n",
    "    #print('Values in LH_Model',arr4)\n",
    "    orignal[:,:]=arr5\n",
    "    _, pred5 = torch.max(output5, 1)\n",
    "    np.savetxt(\"output5.csv\", orignal, delimiter=\", \",header='0,1,2,3,4,5,6,7,8,9',newline='\\n')\n",
    "    #print(orignal)\n",
    "    print(len(Orignal_input))\n",
    "    print('Class Prediction Using LL-Band=',pred1)\n",
    "    print('Class Prediction Using LH-Band=',pred2)\n",
    "    print('Class Prediction Using HL-Band=',pred3)\n",
    "    print('Class Prediction Using HH-Band=',pred4)\n",
    "    print('Class Prediction Using Orignal_Images=',pred5)\n",
    "    y=output1+output2+output3+output4\n",
    "    y=y/4\n",
    "    print('Average Value of Bands= \\n',y)\n",
    "    print('Maximum Value with class= \\n',torch.max(y,1))\n",
    "    i=i+1\n",
    "    \n",
    "total=0\n",
    "correct=0\n",
    "for data in train_loader:\n",
    "    #print(\"Length of data\",len(data))\n",
    "        \n",
    "    LL_input,LH_input,HL_input,HH_input,Orignal_input = data\n",
    "    LL_input = LL_input.view(LL_input.shape[0], -1)\n",
    "    LH_input = LH_input.view(LH_input.shape[0], -1)\n",
    "    HL_input = HL_input.view(HL_input.shape[0], -1)\n",
    "    HH_input = HH_input.view(HH_input.shape[0], -1)\n",
    "    Orignal_input = Orignal_input.view(Orignal_input.shape[0], -1) \n",
    "    #rint(Orignal_input.shape)\n",
    "    Orignaly_input=torch.tensor(Orignaly_input)\n",
    "   # Orignaly_input=Orignaly_input.cpu().clone().detach()\n",
    "    output1 = model1(Orignal_input)\n",
    "    _, pred1 = torch.max(output1, 1)\n",
    "    \n",
    "    total += Orignaly_input.size(0)\n",
    "   # print(pred1)\n",
    "    correct += (pred1== Orignaly_input).sum().item()\n",
    "print('Test Accuracy of the LL_Band_model on the 10000 Orignal test images: {} %'.format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "branchpytorch",
   "language": "python",
   "name": "branchpytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
